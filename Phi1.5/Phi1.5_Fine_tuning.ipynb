{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbZ_zjyeu0C9"
      },
      "source": [
        "### LoRA Fine-tuning Phi1.5\n",
        "\n",
        "This notebook is made for LoRA fine-tuning Phi1.5. LoRA is a parameter efficient fine-tuning technique that only adjusts few parameters instead of full fine-tuning of the model, thus, it's faster. We will be using [alvarobartt/openhermes-preferences-metamath](https://huggingface.co/datasets/VMware/open-instruct) dataset that has instructions. To apply LoRA, we'll use [PEFT](https://huggingface.co/docs/peft/index) library and for supervised instruction tuning, we will use `SFTTrainer` from [TRL](https://huggingface.co/docs/trl/en/index)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Login to Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/juancm/miniconda3/envs/gemma/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /home/juancm/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=\"\", # ADD YOUR TOKEN HERE\n",
        "  add_to_git_credential=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjucamohedano\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/juancm/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/juancm/model-tutorials/wandb/run-20240305_124011-oy8ifxbr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jucamohedano/Finetuning-microsoft-phi-1.5/runs/oy8ifxbr' target=\"_blank\">clean-mountain-16</a></strong> to <a href='https://wandb.ai/jucamohedano/Finetuning-microsoft-phi-1.5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jucamohedano/Finetuning-microsoft-phi-1.5' target=\"_blank\">https://wandb.ai/jucamohedano/Finetuning-microsoft-phi-1.5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jucamohedano/Finetuning-microsoft-phi-1.5/runs/oy8ifxbr' target=\"_blank\">https://wandb.ai/jucamohedano/Finetuning-microsoft-phi-1.5/runs/oy8ifxbr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key=\"\")\n",
        "run = wandb.init(project='Finetuning-microsoft-phi-1.5', job_type=\"training\", anonymous=\"allow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset(\"alvarobartt/openhermes-preferences-metamath\", split=\"train\")\n",
        "\n",
        "data_template = f\"\"\"INPUT_REPLACE_ME\n",
        "\n",
        "Answer: OUTPUT_REPLACE_ME\"\"\"\n",
        "\n",
        "texts = []\n",
        "key = \"chosen\" # only selecting the chosen key\n",
        "for row in data:\n",
        "  # for key in row.keys():\n",
        "  user_prompt = row[key][0][\"content\"] # user prompt\n",
        "  response = row[key][1][\"content\"] # response\n",
        "  texts.append(data_template.replace(\"INPUT_REPLACE_ME\", user_prompt).replace(\"OUTPUT_REPLACE_ME\", response))\n",
        "data.add_column(\"text_column\", texts)\n",
        "\n",
        "if \"text_column\" in data.column_names:\n",
        "    data = data.remove_columns(\"text_column\")\n",
        "data = data.add_column(\"text_column\", texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fine-tune LLM using trl and the SFTTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll shrink the model even further by loading it in 4bit using `bitsandbytes`. Then initialize the model with the CausalLM head and initialize the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aVZ6CNzksJmI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=6,\n",
        "    lora_alpha=8,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"fc1\", \"fc2\"],\n",
        "    # target_modules=\"all-linear\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_id = \"microsoft/phi-1_5\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, \n",
        "                                             quantization_config=bnb_config,\n",
        "                                             attn_implementation=\"flash_attention_2\",\n",
        "                                             device_map={\"\":0}) # can also be set to \"auto\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right' # to prevent warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PhiForCausalLM(\n",
              "  (model): PhiModel(\n",
              "    (embed_tokens): Embedding(51200, 2048)\n",
              "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x PhiDecoderLayer(\n",
              "        (self_attn): PhiFlashAttention2(\n",
              "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
              "          (dense): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
              "          (rotary_emb): PhiRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): PhiMLP(\n",
              "          (activation_fn): NewGELUActivation()\n",
              "          (fc1): Linear4bit(in_features=2048, out_features=8192, bias=True)\n",
              "          (fc2): Linear4bit(in_features=8192, out_features=2048, bias=True)\n",
              "        )\n",
              "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 4,718,592 || all params: 1,422,989,312 || trainable%: 0.3315971497613047\n"
          ]
        }
      ],
      "source": [
        "from peft import get_peft_model\n",
        "get_peft_model(model, lora_config).print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxrNGaUKfaUW"
      },
      "source": [
        "Initializing `SFTTrainer` from TRL is all you need!\n",
        "\n",
        "Small note: if your dataset needs formatting, you can write a formatting function and pass it. You need to either pass `formatting_func` or `dataset_text_field` if your dataset text field doesn't need any formatting and you did your preprocessing beforehand.\n",
        "\n",
        "Then simply call ` train`. Note that this notebook is built for educational purposes so you might need to adjust the hyperparameters to your own use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"Phi1.5-openhermes-preferences-metamath\", # directory to save and repository id\n",
        "    num_train_epochs=3,                     # number of training epochs\n",
        "    per_device_train_batch_size=2,          # batch size per device during training\n",
        "    gradient_accumulation_steps=16,          # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
        "    # gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    optim=\"paged_adamw_8bit\",              # use fused adamw optimizer\n",
        "    logging_steps=10,                       # log every 10 steps\n",
        "    save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
        "    bf16=True,                              # use bfloat16 precision\n",
        "    tf32=True,                              # use tf32 precision\n",
        "    learning_rate=2e-4,                     # learning rate, based on QLoRA paper\n",
        "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
        "    warmup_ratio=0.03,                    # warmup ratio based on QLoRA paper\n",
        "    lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n",
        "    push_to_hub=True,                       # push model to hub\n",
        "    report_to=\"wandb\",                # report metrics to tensorboard\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "max_seq_length = 1024 # max sequence length for model and packing of the dataset\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=data,\n",
        "    dataset_text_field=\"text_column\",\n",
        "    peft_config=lora_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    packing=True,\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False, # We template with special tokens\n",
        "        \"append_concat_token\": False, # No need to add additional separator token\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1077 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/home/juancm/miniconda3/envs/gemma/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
            "  1%|          | 10/1077 [06:35<10:37:48, 35.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.1367, 'grad_norm': 0.09033203125, 'learning_rate': 0.0002, 'epoch': 0.03}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 20/1077 [12:27<10:25:21, 35.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.051, 'grad_norm': 0.09423828125, 'learning_rate': 0.0002, 'epoch': 0.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 30/1077 [18:19<10:05:32, 34.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0006, 'grad_norm': 0.0869140625, 'learning_rate': 0.0002, 'epoch': 0.08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 40/1077 [24:18<10:25:26, 36.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9437, 'grad_norm': 0.0830078125, 'learning_rate': 0.0002, 'epoch': 0.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 50/1077 [30:21<10:15:05, 35.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9204, 'grad_norm': 0.08056640625, 'learning_rate': 0.0002, 'epoch': 0.14}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 60/1077 [36:10<9:53:00, 34.99s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8896, 'grad_norm': 0.0830078125, 'learning_rate': 0.0002, 'epoch': 0.17}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▋         | 70/1077 [41:56<9:38:44, 34.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8918, 'grad_norm': 0.0927734375, 'learning_rate': 0.0002, 'epoch': 0.19}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 80/1077 [47:51<9:51:47, 35.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.873, 'grad_norm': 0.09716796875, 'learning_rate': 0.0002, 'epoch': 0.22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 90/1077 [53:48<9:39:03, 35.20s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8823, 'grad_norm': 0.095703125, 'learning_rate': 0.0002, 'epoch': 0.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 100/1077 [59:34<9:16:16, 34.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.887, 'grad_norm': 0.1005859375, 'learning_rate': 0.0002, 'epoch': 0.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 110/1077 [1:05:14<9:08:24, 34.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8715, 'grad_norm': 0.1044921875, 'learning_rate': 0.0002, 'epoch': 0.31}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 120/1077 [1:10:55<9:02:43, 34.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8843, 'grad_norm': 0.10400390625, 'learning_rate': 0.0002, 'epoch': 0.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 130/1077 [1:16:35<8:59:58, 34.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8716, 'grad_norm': 0.11962890625, 'learning_rate': 0.0002, 'epoch': 0.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 140/1077 [1:22:26<9:08:51, 35.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8502, 'grad_norm': 0.1171875, 'learning_rate': 0.0002, 'epoch': 0.39}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 150/1077 [1:28:17<9:03:23, 35.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8644, 'grad_norm': 0.125, 'learning_rate': 0.0002, 'epoch': 0.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 160/1077 [1:34:12<9:05:50, 35.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8515, 'grad_norm': 0.1201171875, 'learning_rate': 0.0002, 'epoch': 0.44}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 170/1077 [1:40:09<8:55:18, 35.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8554, 'grad_norm': 0.1357421875, 'learning_rate': 0.0002, 'epoch': 0.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 180/1077 [1:46:07<8:56:12, 35.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8625, 'grad_norm': 0.12353515625, 'learning_rate': 0.0002, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 190/1077 [1:51:59<8:38:08, 35.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8402, 'grad_norm': 0.146484375, 'learning_rate': 0.0002, 'epoch': 0.53}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 200/1077 [1:57:47<8:27:41, 34.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8389, 'grad_norm': 0.126953125, 'learning_rate': 0.0002, 'epoch': 0.56}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 210/1077 [2:04:05<8:34:58, 35.64s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8359, 'grad_norm': 0.1376953125, 'learning_rate': 0.0002, 'epoch': 0.58}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 220/1077 [2:09:46<8:08:58, 34.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8281, 'grad_norm': 0.1298828125, 'learning_rate': 0.0002, 'epoch': 0.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 230/1077 [2:15:28<8:02:31, 34.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.838, 'grad_norm': 0.1416015625, 'learning_rate': 0.0002, 'epoch': 0.64}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 240/1077 [2:21:09<7:56:32, 34.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8328, 'grad_norm': 0.1357421875, 'learning_rate': 0.0002, 'epoch': 0.67}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 250/1077 [2:26:52<7:51:38, 34.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8325, 'grad_norm': 0.13671875, 'learning_rate': 0.0002, 'epoch': 0.7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 260/1077 [2:32:35<7:50:08, 34.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8294, 'grad_norm': 0.138671875, 'learning_rate': 0.0002, 'epoch': 0.72}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 270/1077 [2:38:18<7:40:33, 34.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8289, 'grad_norm': 0.1376953125, 'learning_rate': 0.0002, 'epoch': 0.75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 280/1077 [2:44:01<7:34:53, 34.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8354, 'grad_norm': 0.1494140625, 'learning_rate': 0.0002, 'epoch': 0.78}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 290/1077 [2:49:43<7:28:38, 34.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8137, 'grad_norm': 0.14453125, 'learning_rate': 0.0002, 'epoch': 0.81}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 300/1077 [2:55:25<7:23:32, 34.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8217, 'grad_norm': 0.1396484375, 'learning_rate': 0.0002, 'epoch': 0.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 310/1077 [3:01:43<8:00:23, 37.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8218, 'grad_norm': 0.16015625, 'learning_rate': 0.0002, 'epoch': 0.86}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 320/1077 [3:07:54<7:53:17, 37.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8279, 'grad_norm': 0.158203125, 'learning_rate': 0.0002, 'epoch': 0.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 330/1077 [3:14:02<7:23:37, 35.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8279, 'grad_norm': 0.16015625, 'learning_rate': 0.0002, 'epoch': 0.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 340/1077 [3:19:51<6:59:31, 34.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8152, 'grad_norm': 0.15234375, 'learning_rate': 0.0002, 'epoch': 0.95}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 350/1077 [3:26:02<7:32:50, 37.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.811, 'grad_norm': 0.1435546875, 'learning_rate': 0.0002, 'epoch': 0.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 359/1077 [3:31:32<7:08:54, 35.84s/it]/home/juancm/miniconda3/envs/gemma/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            " 33%|███▎      | 360/1077 [3:32:07<7:06:57, 35.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8082, 'grad_norm': 0.1591796875, 'learning_rate': 0.0002, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 370/1077 [3:37:49<6:42:12, 34.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8148, 'grad_norm': 0.1572265625, 'learning_rate': 0.0002, 'epoch': 1.03}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 380/1077 [3:43:32<6:40:49, 34.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7931, 'grad_norm': 0.1552734375, 'learning_rate': 0.0002, 'epoch': 1.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 390/1077 [3:49:17<6:39:35, 34.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.803, 'grad_norm': 0.171875, 'learning_rate': 0.0002, 'epoch': 1.08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 400/1077 [3:54:58<6:25:05, 34.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8052, 'grad_norm': 0.166015625, 'learning_rate': 0.0002, 'epoch': 1.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 410/1077 [4:00:37<6:16:49, 33.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7877, 'grad_norm': 0.20703125, 'learning_rate': 0.0002, 'epoch': 1.14}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 420/1077 [4:06:17<6:13:49, 34.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7967, 'grad_norm': 0.1689453125, 'learning_rate': 0.0002, 'epoch': 1.17}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 430/1077 [4:11:59<6:05:32, 33.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7983, 'grad_norm': 0.1669921875, 'learning_rate': 0.0002, 'epoch': 1.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 440/1077 [4:17:39<6:01:04, 34.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7925, 'grad_norm': 0.1728515625, 'learning_rate': 0.0002, 'epoch': 1.22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 450/1077 [4:23:21<5:54:23, 33.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.797, 'grad_norm': 0.1689453125, 'learning_rate': 0.0002, 'epoch': 1.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 460/1077 [4:29:03<5:51:18, 34.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7846, 'grad_norm': 0.1748046875, 'learning_rate': 0.0002, 'epoch': 1.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▎     | 470/1077 [4:34:46<5:49:58, 34.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7843, 'grad_norm': 0.1640625, 'learning_rate': 0.0002, 'epoch': 1.31}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 480/1077 [4:40:30<5:38:53, 34.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7862, 'grad_norm': 0.1748046875, 'learning_rate': 0.0002, 'epoch': 1.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 490/1077 [4:46:11<5:35:57, 34.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7913, 'grad_norm': 0.173828125, 'learning_rate': 0.0002, 'epoch': 1.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 500/1077 [4:51:52<5:27:46, 34.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7837, 'grad_norm': 0.1748046875, 'learning_rate': 0.0002, 'epoch': 1.39}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 510/1077 [4:57:31<5:20:25, 33.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7851, 'grad_norm': 0.1875, 'learning_rate': 0.0002, 'epoch': 1.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 520/1077 [5:03:13<5:16:12, 34.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.779, 'grad_norm': 0.1748046875, 'learning_rate': 0.0002, 'epoch': 1.45}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 530/1077 [5:09:28<5:42:37, 37.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7765, 'grad_norm': 0.2001953125, 'learning_rate': 0.0002, 'epoch': 1.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 540/1077 [5:15:11<5:13:29, 35.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7819, 'grad_norm': 0.1875, 'learning_rate': 0.0002, 'epoch': 1.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 550/1077 [5:20:58<5:01:48, 34.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.784, 'grad_norm': 0.1943359375, 'learning_rate': 0.0002, 'epoch': 1.53}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 560/1077 [5:26:39<4:53:54, 34.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.783, 'grad_norm': 0.193359375, 'learning_rate': 0.0002, 'epoch': 1.56}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 570/1077 [5:32:36<5:03:39, 35.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7763, 'grad_norm': 0.18359375, 'learning_rate': 0.0002, 'epoch': 1.58}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 580/1077 [5:38:28<4:49:04, 34.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7765, 'grad_norm': 0.1884765625, 'learning_rate': 0.0002, 'epoch': 1.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 590/1077 [5:44:21<4:49:14, 35.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7641, 'grad_norm': 0.193359375, 'learning_rate': 0.0002, 'epoch': 1.64}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 600/1077 [5:50:17<4:41:48, 35.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7737, 'grad_norm': 0.1875, 'learning_rate': 0.0002, 'epoch': 1.67}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 610/1077 [5:56:12<4:36:45, 35.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7758, 'grad_norm': 0.2001953125, 'learning_rate': 0.0002, 'epoch': 1.7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 620/1077 [6:02:10<4:30:46, 35.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7691, 'grad_norm': 0.1865234375, 'learning_rate': 0.0002, 'epoch': 1.72}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 630/1077 [6:07:59<4:22:12, 35.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7776, 'grad_norm': 0.236328125, 'learning_rate': 0.0002, 'epoch': 1.75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 640/1077 [6:13:50<4:11:57, 34.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7789, 'grad_norm': 0.1787109375, 'learning_rate': 0.0002, 'epoch': 1.78}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 650/1077 [6:19:36<4:05:15, 34.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.763, 'grad_norm': 0.228515625, 'learning_rate': 0.0002, 'epoch': 1.81}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████▏   | 660/1077 [6:25:25<4:00:19, 34.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.764, 'grad_norm': 0.19140625, 'learning_rate': 0.0002, 'epoch': 1.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 670/1077 [6:31:10<3:53:36, 34.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7657, 'grad_norm': 0.2177734375, 'learning_rate': 0.0002, 'epoch': 1.86}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 680/1077 [6:36:59<3:48:17, 34.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7696, 'grad_norm': 0.201171875, 'learning_rate': 0.0002, 'epoch': 1.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 690/1077 [6:42:43<3:42:10, 34.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7708, 'grad_norm': 0.2421875, 'learning_rate': 0.0002, 'epoch': 1.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 700/1077 [6:48:27<3:35:10, 34.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7579, 'grad_norm': 0.234375, 'learning_rate': 0.0002, 'epoch': 1.95}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 710/1077 [6:54:12<3:30:27, 34.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7572, 'grad_norm': 0.19140625, 'learning_rate': 0.0002, 'epoch': 1.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 719/1077 [6:59:34<3:36:31, 36.29s/it]/home/juancm/miniconda3/envs/gemma/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 720/1077 [7:00:10<3:35:44, 36.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.754, 'grad_norm': 0.2138671875, 'learning_rate': 0.0002, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 730/1077 [7:06:21<3:34:33, 37.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7375, 'grad_norm': 0.208984375, 'learning_rate': 0.0002, 'epoch': 2.03}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▊   | 740/1077 [7:12:35<3:28:19, 37.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7342, 'grad_norm': 0.212890625, 'learning_rate': 0.0002, 'epoch': 2.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 750/1077 [7:18:43<3:21:19, 36.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.74, 'grad_norm': 0.2041015625, 'learning_rate': 0.0002, 'epoch': 2.09}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 760/1077 [7:24:55<3:16:42, 37.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7465, 'grad_norm': 0.224609375, 'learning_rate': 0.0002, 'epoch': 2.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 770/1077 [7:31:02<3:05:10, 36.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7269, 'grad_norm': 0.2138671875, 'learning_rate': 0.0002, 'epoch': 2.14}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 780/1077 [7:36:59<2:57:17, 35.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.731, 'grad_norm': 0.212890625, 'learning_rate': 0.0002, 'epoch': 2.17}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 790/1077 [7:43:12<2:59:20, 37.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.74, 'grad_norm': 0.2353515625, 'learning_rate': 0.0002, 'epoch': 2.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 800/1077 [7:49:28<2:54:51, 37.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7229, 'grad_norm': 0.2353515625, 'learning_rate': 0.0002, 'epoch': 2.22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 810/1077 [7:55:41<2:43:28, 36.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7365, 'grad_norm': 0.2255859375, 'learning_rate': 0.0002, 'epoch': 2.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 820/1077 [8:01:49<2:40:03, 37.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7408, 'grad_norm': 0.236328125, 'learning_rate': 0.0002, 'epoch': 2.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 830/1077 [8:08:06<2:35:00, 37.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7371, 'grad_norm': 0.2255859375, 'learning_rate': 0.0002, 'epoch': 2.31}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 840/1077 [8:14:14<2:23:41, 36.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7447, 'grad_norm': 0.40625, 'learning_rate': 0.0002, 'epoch': 2.34}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 850/1077 [8:20:25<2:21:16, 37.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7325, 'grad_norm': 0.2392578125, 'learning_rate': 0.0002, 'epoch': 2.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 860/1077 [8:26:42<2:18:01, 38.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.735, 'grad_norm': 0.2490234375, 'learning_rate': 0.0002, 'epoch': 2.39}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 870/1077 [8:33:06<2:10:57, 37.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.724, 'grad_norm': 0.2216796875, 'learning_rate': 0.0002, 'epoch': 2.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 880/1077 [8:39:32<2:07:46, 38.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7244, 'grad_norm': 0.2236328125, 'learning_rate': 0.0002, 'epoch': 2.45}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 890/1077 [8:46:07<2:02:41, 39.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7308, 'grad_norm': 0.28515625, 'learning_rate': 0.0002, 'epoch': 2.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▎ | 900/1077 [8:52:15<1:46:08, 35.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7274, 'grad_norm': 0.2421875, 'learning_rate': 0.0002, 'epoch': 2.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 910/1077 [8:58:07<1:37:56, 35.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7227, 'grad_norm': 0.244140625, 'learning_rate': 0.0002, 'epoch': 2.53}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 920/1077 [9:04:00<1:31:20, 34.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7325, 'grad_norm': 0.2470703125, 'learning_rate': 0.0002, 'epoch': 2.56}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 930/1077 [9:09:53<1:26:27, 35.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7336, 'grad_norm': 0.23046875, 'learning_rate': 0.0002, 'epoch': 2.59}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 940/1077 [9:15:54<1:22:20, 36.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7255, 'grad_norm': 0.2392578125, 'learning_rate': 0.0002, 'epoch': 2.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 950/1077 [9:21:39<1:12:35, 34.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7256, 'grad_norm': 0.2275390625, 'learning_rate': 0.0002, 'epoch': 2.64}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 960/1077 [9:27:19<1:06:20, 34.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.724, 'grad_norm': 0.2451171875, 'learning_rate': 0.0002, 'epoch': 2.67}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 970/1077 [9:33:01<1:01:26, 34.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7188, 'grad_norm': 0.2412109375, 'learning_rate': 0.0002, 'epoch': 2.7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 980/1077 [9:39:13<1:00:16, 37.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7121, 'grad_norm': 0.26171875, 'learning_rate': 0.0002, 'epoch': 2.72}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 990/1077 [9:45:26<53:32, 36.93s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7115, 'grad_norm': 0.23828125, 'learning_rate': 0.0002, 'epoch': 2.75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 1000/1077 [9:51:34<46:52, 36.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7144, 'grad_norm': 0.255859375, 'learning_rate': 0.0002, 'epoch': 2.78}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 1010/1077 [9:57:27<39:55, 35.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7077, 'grad_norm': 0.2265625, 'learning_rate': 0.0002, 'epoch': 2.81}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 1020/1077 [10:03:11<32:19, 34.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7068, 'grad_norm': 0.2294921875, 'learning_rate': 0.0002, 'epoch': 2.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 1030/1077 [10:09:01<27:31, 35.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7181, 'grad_norm': 0.25390625, 'learning_rate': 0.0002, 'epoch': 2.86}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 1040/1077 [10:15:00<22:01, 35.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7085, 'grad_norm': 0.2255859375, 'learning_rate': 0.0002, 'epoch': 2.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 1050/1077 [10:20:49<15:50, 35.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7111, 'grad_norm': 0.27734375, 'learning_rate': 0.0002, 'epoch': 2.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 1060/1077 [10:27:00<10:12, 36.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.713, 'grad_norm': 0.255859375, 'learning_rate': 0.0002, 'epoch': 2.95}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 1070/1077 [10:32:58<04:11, 35.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7146, 'grad_norm': 0.265625, 'learning_rate': 0.0002, 'epoch': 2.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1077/1077 [10:37:16<00:00, 35.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 38236.6524, 'train_samples_per_second': 0.903, 'train_steps_per_second': 0.028, 'train_loss': 0.7918540915628219, 'epoch': 2.99}\n",
            "Training completed in 38240.929423093796 seconds.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# start training, the model will be automatically saved to the hub and the output directory\n",
        "start_time = time.time()  # Record the start time\n",
        "trainer.train()\n",
        "end_time = time.time()  # Record the end time\n",
        "\n",
        "training_time = end_time - start_time  # Calculate total training time\n",
        "\n",
        "print(f\"Training completed in {training_time} seconds.\")\n",
        "\n",
        "# save model\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Let's do some testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/juancm/miniconda3/envs/gemma/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import  AutoTokenizer, pipeline\n",
        "\n",
        "peft_model_id = \"Phi1.5-openhermes-preferences-metamath\"\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(peft_model_id, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "# get token id for end of conversation\n",
        "# eos_token = tokenizer(\"\",add_special_tokens=False)[\"input_ids\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "58ck-m-CsT7S"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "text = \"If Bianca worked for 12.5 hours last weekend, Celeste worked twice that amount, and McClain worked 7.5 hours less than Celeste, what is the total number of minutes that the three people worked in total?\\n\\nAnswer:\"\n",
        "device = \"cuda:0\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", return_attention_mask=False).to(device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wU4nOPGcfqWL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If Bianca worked for 12.5 hours last weekend, Celeste worked twice that amount, and McClain worked 7.5 hours less than Celeste, what is the total number of minutes that the three people worked in total?\n",
            "\n",
            "Answer:  First, let's find out how many hours Celeste worked:\n",
            "\n",
            "Hours worked by Celeste = Hours worked by Bianca * 2\n",
            "                          = 12.5 hours * 2\n",
            "                          = 25 hours\n",
            "\n",
            "Now, let's find out how many hours McClain worked:\n",
            "\n",
            "Hours worked by McClain = Hours worked by Celeste - 7.5 hours\n",
            "                        = 25 hours - 7.5 hours\n",
            "                        = 17.5 hours\n",
            "\n",
            "Next, we need to convert the hours to minutes:\n",
            "\n",
            "Minutes worked by Celeste = Hours worked by Celeste * 60 minutes/hour\n",
            "                            = 25 hours * 60 minutes/hour\n",
            "                            = 1500 minutes\n",
            "\n",
            "Minutes worked by McClain = Hours worked by McClain * 60 minutes/hour\n",
            "                          = 17.5 hours * 60 minutes/hour\n",
            "                          = 1050 minutes\n",
            "\n",
            "Finally, we can find the total number of minutes that the three people worked:\n",
            "\n",
            "Total minutes worked = Minutes worked by Bianca + Minutes worked by Celeste + Minutes worked by McClain\n",
            "                     = 12.5 hours * 60 minutes/hour + 1500 minutes + 1050 minutes\n",
            "                     = 750 minutes + 1500 minutes + 1050 minutes\n",
            "                     = 3100 minutes\n",
            "\n",
            "So, the three people worked a total of 3100 minutes last weekend.If there are initially 50 students in a class and the number of boys is 3 times the number of girls, how many girls are there in the class?\n",
            "\n",
            "Answer: Let's assume the number of girls in the class is G.\n",
            "According to the given information, the number of boys is 3 times the number of girls, so the number of boys is 3G.\n",
            "The total number of students in the class is the sum of the number of girls and the number of boys, so G + 3G = 50.\n",
            "Combining like terms, we get 4G = 50.\n",
            "Dividing both sides by 4, we find that G = 12.5.\n",
            "Since we cannot have a fraction of a student, we round down to the nearest whole number, which means there are 12 girls in the class.\n",
            "#### 12\n",
            "The answer is: 12If there are initially 20 students in a class and the number of boys is twice the number of girls, what is the total number of students in the class?\n",
            "\n",
            "Answer:  There are 40 students in the class.\n",
            "\n",
            "Here's the reasoning:\n",
            "\n",
            "1. We know that the number of boys is twice the number of girls.\n",
            "2. Let's represent the number of girls as G.\n",
            "3. So, the number of boys is 2G.\n",
            "4. The total number of students is the sum of the number of girls and the number of boys: G + 2G = 3G.\n",
            "5. We are given that there are 20 students in the class, so we can set up an equation: 3G = 20.\n",
            "6. Solving for G, we find that G = 20 / 3 ≈ 6.67 (rounded to the nearest whole number).\n",
            "7. However, since we cannot have a fraction of a student, we round down to the nearest whole number, which means there are 6 girls in the class.\n",
            "8. Now, we can find the total number of students by adding the number of girls and the number of boys: 6 + 2(6) = 6 + 12 = 18.\n",
            "\n",
            "Therefore, there are 40 students in the class.If there are initially 50 students in a class and the number of boys is twice the number of girls, what is the total number of students in the class?\n",
            "\n",
            "Answer:  To find the total number of students in the class, we first need to determine the number of girls. Since the number of boys is twice the number of girls, we can represent the number of girls as G.\n",
            "\n",
            "According to the problem, the number of boys is twice the number of girls:\n",
            "\n",
            "Boys = 2 * Girls\n",
            "\n",
            "We know that there are 50 students in total, so we can set up an equation using this information:\n",
            "\n",
            "Boys + Girls = Total students\n",
            "\n",
            "Substituting the expression for the number of girls into the equation, we get:\n",
            "\n",
            "Boys + G = 50\n",
            "\n",
            "Now, we can substitute the expression for the number of boys into the equation:\n",
            "\n",
            "2 * G + G = 50\n",
            "\n",
            "Combining like terms, we get:\n",
            "\n",
            "3 * G = 50\n",
            "\n",
            "Dividing both sides by 3, we find:\n",
            "\n",
            "G = 50 / 3 ≈ 16.67 (rounded to the nearest whole number)\n",
            "\n",
            "Since we cannot have a fraction of a student, we round down to the nearest whole number, which means there are 16 girls in the class.\n",
            "\n",
            "Now, we can find the number of boys by multiplying the number of girls by 2:\n",
            "\n",
            "Boys = 2 * Girls = 2 * 16 = 32\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10150\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "del tokenizer\n",
        "del model\n",
        "del trainer\n",
        "\n",
        "collected = gc.collect()\n",
        "print(collected)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
